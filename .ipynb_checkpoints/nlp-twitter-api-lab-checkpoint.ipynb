{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# NLP Using the Twitter API: Guided Lab\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<img src=\"https://snag.gy/RNAEgP.jpg\" width=\"600\">\n",
    "\n",
    "### Can we correctly identify which of these two old men tweeted what?\n",
    "\n",
    "> *Note: this lab is intended to be a guided lab until the independent practice questions.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "---\n",
    "\n",
    "We are going to attempt to classify whether a tweet comes from Trump or Sanders.  This lab involves multiple steps:\n",
    "- Create a developer account on Twitter\n",
    "- Create a method to pull a list of tweets from the Twitter API\n",
    "- Perform proper preprocessing on our text\n",
    "- Engineer sentiment feature in our dataset using TextBlob\n",
    "- Explore supervised classification techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter API Developer Registration\n",
    "---\n",
    "\n",
    "If you haven't registered a Twitter account yet, this is a requirement in order to have a \"developer\" account.\n",
    "\n",
    "[Twitter Sign Up](https://twitter.com/signup)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an \"App\"\n",
    "\n",
    "---\n",
    "\n",
    "![](https://snag.gy/HPBQbJ.jpg)\n",
    "\n",
    "Go to Twitter and register an \"app\" [apps.twitter.com](https://apps.twitter.com/).\n",
    "\n",
    "> **Note**: For the required website field you can put a placeholder.\n",
    "\n",
    "After you set up our app, you will only need to reference the corresponding keys Twitter generates for our app.  These are the keys that we will use with our application to communicate with the Twitter API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Python Twitter API library\n",
    "\n",
    "---\n",
    "\n",
    "Someone was nice enough to build a Python libary for us. It makes pulling tweets simple: we only need to plug in our keys and start collecting data. The library we will be using is provided by [Python Twitter Tools](http://mike.verdone.ca/twitter/).\n",
    "\n",
    "To install it, just run the next frame (there is no conda package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twitter in /anaconda/lib/python2.7/site-packages\r\n",
      "Requirement already satisfied: python-twitter in /anaconda/lib/python2.7/site-packages\r\n",
      "Requirement already satisfied: requests in /anaconda/lib/python2.7/site-packages (from python-twitter)\r\n",
      "Requirement already satisfied: requests-oauthlib in /anaconda/lib/python2.7/site-packages (from python-twitter)\r\n",
      "Requirement already satisfied: future in /anaconda/lib/python2.7/site-packages (from python-twitter)\r\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in /anaconda/lib/python2.7/site-packages (from requests-oauthlib->python-twitter)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install twitter python-twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Boring Twitter Rules\n",
    "---\n",
    "\n",
    "**Twitter notifies you they will rate limit your requests:**\n",
    "\n",
    ">THERE ARE LIMITS TO THE AMOUNT OF TIMES YOU CAN HIT THE API PER 15 MINUTE WINDOW. BEWARE!\n",
    "\n",
    "Here's a quick overview of what Twitter says are \"[the rules](https://dev.twitter.com/rest/public/rate-limiting)\":\n",
    "\n",
    "![](https://snag.gy/yJ6vIH.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Application Keys\n",
    "---\n",
    "\n",
    "Take note of your application keys you will use to connect to Twitter and mine tweets from the official Bernie Sanders and Donald Trump twitter accounts:\n",
    "\n",
    "![](https://snag.gy/H1djQK.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TweetMiner` class structure\n",
    "\n",
    "---\n",
    "\n",
    "The following code will get you up and running, providing connectivity to twitter. The class has the ability to make requests and can eventually transform the JSON responses into DataFrames.\n",
    "\n",
    "This is a great example of using object-oriented Python to organize our code!\n",
    "\n",
    "> **Note:** \"request_limit\" is used in this class to limit the number of tweets that are pulled per instance request.  Setting it to something lower until you've worked the bugs out of your request, and captured the data you want, is essential to avoiding the rate limit blocks.\n",
    "\n",
    "### Twitter API key setup\n",
    "\n",
    "Fill the information below in with the keys for your account.\n",
    "\n",
    "- **consumer_key** - Find this in your app page under the \"Keys and Access Tokens\"\n",
    "- **consumer_secret** - Right under **consumer_key** in the \"Keys and Access Tokens\" tab\n",
    "- **access_token_key** - You will need to click the button to generate tokens to get this\n",
    "- **access_token_secret** - Also available after you generate tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter, re, datetime, pandas as pd\n",
    "\n",
    "twitter_keys = {\n",
    "    'consumer_key':        'gNh9ECBWkSJlxMDWQDhSq4zGA',\n",
    "    'consumer_secret':     'anVMk1BJd1ai58MOPpItIVIM3kpLu8OBgw01ZBn3KSN1espRlL',\n",
    "    'access_token_key':    '898996122479468545-atpLi5baU2fmCyddsa8bEMUD70tNRaE',\n",
    "    'access_token_secret': 'fL5qxmKYn39VZDYxNVG3XgZLJXE1OqWp4MvqGKwyCaiO7'\n",
    "}\n",
    "\n",
    "api = twitter.Api(\n",
    "    consumer_key         =   twitter_keys['consumer_key'],\n",
    "    consumer_secret      =   twitter_keys['consumer_secret'],\n",
    "    access_token_key     =   twitter_keys['access_token_key'],\n",
    "    access_token_secret  =   twitter_keys['access_token_secret']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## We've build a function below that uses this python twitter package. Before we work with the function, let's\n",
    "## take a look at some of the fundamental pieces of the package.\n",
    "\n",
    "# This call will fetch the most recent tweet \"statuses\". Tweet statuses are objects that hold tweet id's,\n",
    "# tweet text, tweeter name, when a tweet was created etc. \n",
    "# Here, we explicitly define that we'd like to pull the last 20 tweets for Bernie Sanders. \n",
    "x = api.GetUserTimeline(screen_name=\"berniesanders\", count=20)\n",
    "# Below we've pulled in a max_id parameter. \n",
    "# If max Id pertains to a tweet made 40 tweets ago, we'll pull tweet tweets from 40 to 60 tweets ago (since count=20).\n",
    "y = api.GetUserTimeline(screen_name=\"berniesanders\", count=20, max_id=900003837913817088)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Status(ID=900003837913817088, ScreenName=BernieSanders, Created=Tue Aug 22 14:36:50 +0000 2017, Text=u'LIVE: Join Bernie for a town hall in Ohio to talk about our priorities on health care, wages and infrastructure: https://t.co/6wkxdUxVbN'),\n",
       " Status(ID=899730088450719747, ScreenName=BernieSanders, Created=Mon Aug 21 20:29:03 +0000 2017, Text=u'RT @evanmcmurry: .@BernieSanders in Indianapolis: \"We\\'re not going to rebuild the shrinking middle class unless we rebuild the trade union\\u2026'),\n",
       " Status(ID=899729416569356288, ScreenName=BernieSanders, Created=Mon Aug 21 20:26:23 +0000 2017, Text=u'RT @ABCPolitics: .@BernieSanders: \"What an embarrassment it is that we have a president who cannot condemn in unequivocal terms\" white supr\\u2026'),\n",
       " Status(ID=899727519460593665, ScreenName=BernieSanders, Created=Mon Aug 21 20:18:51 +0000 2017, Text=u'We defeated the disastrous Republican health care plan. Now we must work together to guarantee health care to all. https://t.co/4uGxKpz73S'),\n",
       " Status(ID=899726409362550784, ScreenName=BernieSanders, Created=Mon Aug 21 20:14:26 +0000 2017, Text=u'WATCH LIVE: Bernie speaks at the @GoodJobsNation rally in Indianapolis to call on Trump to protect workers: https://t.co/w5j1FVh7Hm'),\n",
       " Status(ID=899641884498374656, ScreenName=BernieSanders, Created=Mon Aug 21 14:38:34 +0000 2017, Text=u'I am heading to Indiana, Michigan and Ohio this week to make one simple point: ALL Americans are entitled to health care as a right.'),\n",
       " Status(ID=899633553868283905, ScreenName=BernieSanders, Created=Mon Aug 21 14:05:28 +0000 2017, Text=u'RT @FortuneMagazine: An exclusive op-ed from Senator @BernieSanders: \"Why Medicare-for-all is good for business\" https://t.co/eVEGmr0VEZ'),\n",
       " Status(ID=899628600575619074, ScreenName=BernieSanders, Created=Mon Aug 21 13:45:47 +0000 2017, Text=u'Join me, Chuck Jones and @GoodJobsNation today in Indianapolis to stand up for good jobs and livable wages: https://t.co/tIABiB9cNC'),\n",
       " Status(ID=898298120865542144, ScreenName=BernieSanders, Created=Thu Aug 17 21:38:56 +0000 2017, Text=u'We must now stand together as a global community to address the threat of terrorism and resist efforts to divide us up.'),\n",
       " Status(ID=898298051537772545, ScreenName=BernieSanders, Created=Thu Aug 17 21:38:39 +0000 2017, Text=u'My thoughts are with the people of Barcelona, the victims of this horrific terror attack and their families.'),\n",
       " Status(ID=897521129304330240, ScreenName=BernieSanders, Created=Tue Aug 15 18:11:27 +0000 2017, Text=u'Immigrants should have a rational path toward citizenship, not just a dark corner to hide in. We must vigorously #DefendDACA.'),\n",
       " Status(ID=897148457764388866, ScreenName=BernieSanders, Created=Mon Aug 14 17:30:35 +0000 2017, Text=u'RT @ajjaffe: \"The long-term solution to the healthcare crisis in America is to make Medicare available to all\" @BernieSanders says @ senior\\u2026'),\n",
       " Status(ID=897110704477675520, ScreenName=BernieSanders, Created=Mon Aug 14 15:00:34 +0000 2017, Text=u'RT @guardian: Most Americans want universal healthcare. What are we waiting for? | Bernie Sanders https://t.co/XHcswiLYGq'),\n",
       " Status(ID=896799314864898048, ScreenName=BernieSanders, Created=Sun Aug 13 18:23:13 +0000 2017, Text=u'The best way for us to truly honor her memory is to make sure that, every day, we continue that struggle.'),\n",
       " Status(ID=896799082429198337, ScreenName=BernieSanders, Created=Sun Aug 13 18:22:17 +0000 2017, Text=u'Heather sacrificed her life in the fight for social and racial justice. She will not be forgotten.'),\n",
       " Status(ID=896798462678900736, ScreenName=BernieSanders, Created=Sun Aug 13 18:19:49 +0000 2017, Text=u'Our condolences go out to the family of Heather Heyer who was killed by a terrorist as she protested Neo-Nazism and white supremacy.'),\n",
       " Status(ID=896448448039452676, ScreenName=BernieSanders, Created=Sat Aug 12 19:08:59 +0000 2017, Text=u'As hate crimes and hostility toward minorities surge, now more than ever we must stand against those who threaten our brothers and sisters.'),\n",
       " Status(ID=896448348416348160, ScreenName=BernieSanders, Created=Sat Aug 12 19:08:36 +0000 2017, Text=u'My thoughts are with those in the Charlottesville community and around the country who have been targeted.'),\n",
       " Status(ID=896448272046460928, ScreenName=BernieSanders, Created=Sat Aug 12 19:08:17 +0000 2017, Text=u'The white nationalist demonstration in #Charlottesville is a reprehensible display of racism and hatred. This has no place in our society.'),\n",
       " Status(ID=893531481116737537, ScreenName=BernieSanders, Created=Fri Aug 04 17:58:00 +0000 2017, Text=u'Bottom line is: if other countries around the world are providing quality health care to all their people, we can do the same.')]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what the Get User Timeline returns: A list of status objects.\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Tue Aug 22 14:36:50 +0000 2017'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Individual status obj\n",
    "y[0].created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "twitter.models.Status"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Type\n",
    "type(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900003837913817088, u'Bernie Sanders', 391, u'LIVE: Join Bernie for a town hall in Ohio to talk about our priorities on health care, wages and infrastructure: https://t.co/6wkxdUxVbN', u'Tue Aug 22 14:36:50 +0000 2017')\n"
     ]
    }
   ],
   "source": [
    "# Here we'll take a look at some of the attributes of the Status object (which we use in our function)\n",
    "print(y[0].id, y[0].user.name, y[0].retweet_count, y[0].text, y[0].created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "0    1\n",
       "0    2\n",
       "Name: handle, dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we create a Tweetminer class that initializes the twitter api with our login credentials.\n",
    "# Additionally, we define a method, mine_user_tweets that allows us to call the GetUserTimeline method\n",
    "# for a user seamlessly. \n",
    "\n",
    "class TweetMiner(object):\n",
    "\n",
    "    result_limit    =   20    \n",
    "    api             =   False\n",
    "    data            =   []\n",
    "    \n",
    "    twitter_keys = {\n",
    "        'consumer_key':        'gNh9ECBWkSJlxMDWQDhSq4zGA',\n",
    "        'consumer_secret':     'anVMk1BJd1ai58MOPpItIVIM3kpLu8OBgw01ZBn3KSN1espRlL',\n",
    "        'access_token_key':    '898996122479468545-atpLi5baU2fmCyddsa8bEMUD70tNRaE',\n",
    "        'access_token_secret': 'fL5qxmKYn39VZDYxNVG3XgZLJXE1OqWp4MvqGKwyCaiO7'\n",
    "    }\n",
    "    \n",
    "    def __init__(self, keys_dict, api, result_limit = 20):\n",
    "        \n",
    "        self.api = api\n",
    "        self.twitter_keys = keys_dict\n",
    "        \n",
    "        self.result_limit = result_limit\n",
    "        \n",
    "\n",
    "    def mine_user_tweets(self, user=\"michaelromanGA\", mine_rewteets=False, max_pages=5, max_id=False):\n",
    "\n",
    "        data           =  []\n",
    "        last_tweet_id  =  False\n",
    "        page           =  1\n",
    "        \n",
    "        while page <= max_pages:\n",
    "            \n",
    "            if last_tweet_id:\n",
    "                statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.result_limit, max_id=max_id)        \n",
    "            else:\n",
    "                statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.result_limit)\n",
    "                \n",
    "            for item in statuses:\n",
    "\n",
    "                mined = {\n",
    "                    'tweet_id':        item.id,\n",
    "                    'handle':          item.user.name,\n",
    "                    'retweet_count':   item.retweet_count,\n",
    "                    'text':            item.text,\n",
    "                    'mined_at':        datetime.datetime.now(),\n",
    "                    'created_at':      item.created_at,\n",
    "                }\n",
    "                \n",
    "                last_tweet_id = item.id\n",
    "                data.append(mined)\n",
    "                \n",
    "            page += 1\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the class\n",
    "---\n",
    "\n",
    "Make sure you pass the keys dictionary and the api as arguments.\n",
    "\n",
    "**Check:** call the object's `mine_user_tweets()` method, providing a user to pull the tweets of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# result limit is the \"count\" argument we tuned earlier. \n",
    "miner = TweetMiner(twitter_keys, api, result_limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We're pulling result_limit * max_pages results = 10 results for Trump and Sanders.\n",
    "# sanders = miner.mine_user_tweets(user=\"berniesanders\", max_pages=5)\n",
    "donald = miner.mine_user_tweets(user=\"realDonaldTrump\", max_pages=5, max_id=748920081942327296)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'created_at': u'Fri Aug 25 19:18:49 +0000 2017',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2017, 8, 25, 16, 33, 33, 500144),\n",
       "  'retweet_count': 4744,\n",
       "  'text': u'I encourage everyone in the path of #HurricaneHarvey to heed the advice &amp; orders of their local and state officials. https://t.co/N6uEWCZUrv',\n",
       "  'tweet_id': 901161964994539520},\n",
       " {'created_at': u'Fri Aug 25 16:02:33 +0000 2017',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2017, 8, 25, 16, 33, 33, 500174),\n",
       "  'retweet_count': 5147,\n",
       "  'text': u'Received a #HurricaneHarvey briefing this morning from Acting @DHSgov Secretary Elaine Duke, @FEMA_Brock,\\u2026 https://t.co/VGdeIdgLbO',\n",
       "  'tweet_id': 901112569322237952},\n",
       " {'created_at': u'Fri Jul 01 16:43:56 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2017, 8, 25, 16, 33, 33, 670511),\n",
       "  'retweet_count': 6727,\n",
       "  'text': u\"These crimes won't be happening if I'm elected POTUS. Killer should have never been here. #AmericaFirst \\nhttps://t.co/XDGKaj0ico\",\n",
       "  'tweet_id': 748920081942327296},\n",
       " {'created_at': u'Fri Jul 01 16:43:56 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2017, 8, 25, 16, 33, 33, 840781),\n",
       "  'retweet_count': 6727,\n",
       "  'text': u\"These crimes won't be happening if I'm elected POTUS. Killer should have never been here. #AmericaFirst \\nhttps://t.co/XDGKaj0ico\",\n",
       "  'tweet_id': 748920081942327296},\n",
       " {'created_at': u'Fri Jul 01 16:43:56 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2017, 8, 25, 16, 33, 34, 26716),\n",
       "  'retweet_count': 6727,\n",
       "  'text': u\"These crimes won't be happening if I'm elected POTUS. Killer should have never been here. #AmericaFirst \\nhttps://t.co/XDGKaj0ico\",\n",
       "  'tweet_id': 748920081942327296},\n",
       " {'created_at': u'Fri Jul 01 16:43:56 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2017, 8, 25, 16, 33, 34, 229469),\n",
       "  'retweet_count': 6727,\n",
       "  'text': u\"These crimes won't be happening if I'm elected POTUS. Killer should have never been here. #AmericaFirst \\nhttps://t.co/XDGKaj0ico\",\n",
       "  'tweet_id': 748920081942327296}]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'handle': u'Donald J. Trump', 'mined_at': datetime.datetime(2017, 8, 25, 11, 31, 53, 526864), 'created_at': u'Fri Aug 25 12:25:10 +0000 2017', 'tweet_id': 901057864516734978, 'text': u\"Strange statement by Bob Corker considering that he is constantly asking me whether or not he should run again in '18. Tennessee not happy!\", 'retweet_count': 7342}\n"
     ]
    }
   ],
   "source": [
    "print donald[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the tweet ouputs to a pandas DataFrame\n",
    "\n",
    "> *Hint: this is as easy as passing it to the DataFrame constructor!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 25 19:18:49 +0000 2017</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2017-08-25 16:31:26.074230</td>\n",
       "      <td>4688</td>\n",
       "      <td>I encourage everyone in the path of #Hurricane...</td>\n",
       "      <td>901161964994539520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Aug 25 16:02:33 +0000 2017</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2017-08-25 16:31:26.074241</td>\n",
       "      <td>5130</td>\n",
       "      <td>Received a #HurricaneHarvey briefing this morn...</td>\n",
       "      <td>901112569322237952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Aug 25 15:46:40 +0000 2017</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2017-08-25 16:31:26.263565</td>\n",
       "      <td>8218</td>\n",
       "      <td>I have spoken w/ @GovAbbott of Texas and @Loui...</td>\n",
       "      <td>901108572041433089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Aug 25 12:25:10 +0000 2017</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2017-08-25 16:31:26.263574</td>\n",
       "      <td>10789</td>\n",
       "      <td>Strange statement by Bob Corker considering th...</td>\n",
       "      <td>901057864516734978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Aug 25 11:32:23 +0000 2017</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2017-08-25 16:31:26.449134</td>\n",
       "      <td>11904</td>\n",
       "      <td>Nick Adams, \"Retaking America\"  \"Best things o...</td>\n",
       "      <td>901044579750825985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fri Aug 25 10:44:17 +0000 2017</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2017-08-25 16:31:26.449144</td>\n",
       "      <td>12530</td>\n",
       "      <td>Few, if any, Administrations have done more in...</td>\n",
       "      <td>901032475111116800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fri Aug 25 10:40:32 +0000 2017</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2017-08-25 16:31:26.628988</td>\n",
       "      <td>14187</td>\n",
       "      <td>General John Kelly is doing a fantastic job as...</td>\n",
       "      <td>901031532164468736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fri Aug 25 10:33:32 +0000 2017</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2017-08-25 16:31:26.629000</td>\n",
       "      <td>13506</td>\n",
       "      <td>If Senate Republicans don't get rid of the Fil...</td>\n",
       "      <td>901029770401546243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fri Aug 25 10:25:06 +0000 2017</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2017-08-25 16:31:27.038811</td>\n",
       "      <td>4257</td>\n",
       "      <td>RT @EricTrump: Honored to speak at the RNC Sum...</td>\n",
       "      <td>901027651216969728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fri Aug 25 03:23:34 +0000 2017</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2017-08-25 16:31:27.038861</td>\n",
       "      <td>8163</td>\n",
       "      <td>RT @GregAbbott_TX: Spoke with Pres. Trump &amp;amp...</td>\n",
       "      <td>900921565868687360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at           handle                   mined_at  \\\n",
       "0  Fri Aug 25 19:18:49 +0000 2017  Donald J. Trump 2017-08-25 16:31:26.074230   \n",
       "1  Fri Aug 25 16:02:33 +0000 2017  Donald J. Trump 2017-08-25 16:31:26.074241   \n",
       "2  Fri Aug 25 15:46:40 +0000 2017  Donald J. Trump 2017-08-25 16:31:26.263565   \n",
       "3  Fri Aug 25 12:25:10 +0000 2017  Donald J. Trump 2017-08-25 16:31:26.263574   \n",
       "4  Fri Aug 25 11:32:23 +0000 2017  Donald J. Trump 2017-08-25 16:31:26.449134   \n",
       "5  Fri Aug 25 10:44:17 +0000 2017  Donald J. Trump 2017-08-25 16:31:26.449144   \n",
       "6  Fri Aug 25 10:40:32 +0000 2017  Donald J. Trump 2017-08-25 16:31:26.628988   \n",
       "7  Fri Aug 25 10:33:32 +0000 2017  Donald J. Trump 2017-08-25 16:31:26.629000   \n",
       "8  Fri Aug 25 10:25:06 +0000 2017  Donald J. Trump 2017-08-25 16:31:27.038811   \n",
       "9  Fri Aug 25 03:23:34 +0000 2017  Donald J. Trump 2017-08-25 16:31:27.038861   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0           4688  I encourage everyone in the path of #Hurricane...   \n",
       "1           5130  Received a #HurricaneHarvey briefing this morn...   \n",
       "2           8218  I have spoken w/ @GovAbbott of Texas and @Loui...   \n",
       "3          10789  Strange statement by Bob Corker considering th...   \n",
       "4          11904  Nick Adams, \"Retaking America\"  \"Best things o...   \n",
       "5          12530  Few, if any, Administrations have done more in...   \n",
       "6          14187  General John Kelly is doing a fantastic job as...   \n",
       "7          13506  If Senate Republicans don't get rid of the Fil...   \n",
       "8           4257  RT @EricTrump: Honored to speak at the RNC Sum...   \n",
       "9           8163  RT @GregAbbott_TX: Spoke with Pres. Trump &amp...   \n",
       "\n",
       "             tweet_id  \n",
       "0  901161964994539520  \n",
       "1  901112569322237952  \n",
       "2  901108572041433089  \n",
       "3  901057864516734978  \n",
       "4  901044579750825985  \n",
       "5  901032475111116800  \n",
       "6  901031532164468736  \n",
       "7  901029770401546243  \n",
       "8  901027651216969728  \n",
       "9  900921565868687360  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(donald)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Create the training data\n",
    "\n",
    "---\n",
    "\n",
    "Let's get our \"mined\" data from the Twitter API.  \n",
    "\n",
    "1. Mine Trump tweets\n",
    "- Create a tweet DataFrame\n",
    "- Mine Sanders tweets\n",
    "- Append the results to our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we only need to \"instantiate\" once.  Then we can call mine_user_tweets as much as we want. Upping result limit\n",
    "# from example above.\n",
    "miner = TweetMiner(twitter_keys, api, result_limit=400)\n",
    "trump_tweets = miner.mine_user_tweets(\"realDonaldTrump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n"
     ]
    }
   ],
   "source": [
    "trump_df = pd.DataFrame(trump_tweets)\n",
    "print trump_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bernie_tweets = miner.mine_user_tweets('berniesanders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n"
     ]
    }
   ],
   "source": [
    "bernie_df = pd.DataFrame(bernie_tweets) \n",
    "print bernie_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.concat([trump_df, bernie_df], axis=0)\n",
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Any interesting ngrams going on with Trump?\n",
    "---\n",
    "\n",
    "Set up a vectorizer from sklearn and fit the text of Trump's tweets with an ngram range from 2 to 4. Figure out what the most common ngrams are.\n",
    "\n",
    "> **Note:** It's up to you whether you want to remove stopwords or not. How does keeping or removing stopwords affect the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'fake news', 59),\n",
       " (u'rt foxandfriends', 29),\n",
       " (u'north korea', 25),\n",
       " (u'united states', 21),\n",
       " (u'great honor', 20),\n",
       " (u'white house', 20),\n",
       " (u'america great', 20),\n",
       " (u'news media', 19),\n",
       " (u'make america', 18),\n",
       " (u'republican senators', 18),\n",
       " (u'fake news media', 18),\n",
       " (u'make america great', 16),\n",
       " (u'honor welcome', 15),\n",
       " (u'president trump', 14),\n",
       " (u'jobs jobs', 13),\n",
       " (u'repeal amp', 13),\n",
       " (u'repeal amp replace', 13),\n",
       " (u'amp replace', 13),\n",
       " (u'working hard', 12),\n",
       " (u'great state', 12)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "# We can use the TfidfVectorizer to find ngrams for us\n",
    "vect = TfidfVectorizer(ngram_range=(2,4), stop_words='english')\n",
    "\n",
    "# Pulls all of trumps tweet text's into one giant string\n",
    "summaries = \"\".join(trump_df['text'])\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "\n",
    "Counter(ngrams_summaries).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the ngrams for Bernie Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'health care', 115),\n",
       " (u'bernie sanders', 54),\n",
       " (u'donald trump', 46),\n",
       " (u'democratic party', 24),\n",
       " (u'working families', 24),\n",
       " (u'wall street', 23),\n",
       " (u'american people', 22),\n",
       " (u'climate change', 20),\n",
       " (u'health insurance', 18),\n",
       " (u'tax breaks', 17),\n",
       " (u'https rt', 16),\n",
       " (u'working people', 16),\n",
       " (u'millions people', 14),\n",
       " (u'minimum wage', 14),\n",
       " (u'guarantee health', 13),\n",
       " (u'guarantee health care', 13),\n",
       " (u'care right', 13),\n",
       " (u'health care right', 13),\n",
       " (u'mr trump', 12),\n",
       " (u'drug companies', 11)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the TfidfVectorizer to find ngrams for us\n",
    "vect = TfidfVectorizer(ngram_range=(2,4), stop_words='english')\n",
    "\n",
    "# Pulls all of trumps tweet text's into one giant string\n",
    "summaries = \"\".join(bernie_df['text'])\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "\n",
    "Counter(ngrams_summaries).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the tweets and building a model\n",
    "\n",
    "---\n",
    "\n",
    "To do classfication we will need to convert the tweets into a set of features.\n",
    "\n",
    "**You will need to:**\n",
    "- Vectorize input text data.\n",
    "- Intialize a model (try Logistic regression).\n",
    "- Train / Predict / cross-validate.\n",
    "- Evaluate the performance of the model.\n",
    "\n",
    "> **Bonus:** you may have noticed that there are website links in the tweets. What additional preprocessing steps can you do before building the model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BONUS\n",
    "# Using the textacy package to do some more comprehensive preprocessing\n",
    "# http://textacy.readthedocs.io/en/latest/\n",
    "# To install: pip install textacy\n",
    "# We're going to take 5 minutes so that you can look through this code and the arguments. Then we'll come together \n",
    "# to talk about as a group.\n",
    "from textacy.preprocess import preprocess_text\n",
    "\n",
    "tweet_text = tweets['text'].values\n",
    "clean_text = [preprocess_text(x, fix_unicode=True, lowercase=True, transliterate=False,\n",
    "                              no_urls=True, no_emails=True, no_phone_numbers=True, no_currency_symbols=True,\n",
    "                              no_punct=True, no_accents=True)\n",
    "              for x in tweet_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ u\"2nd-Grade Teacher Can't Believe How Much Fatter They Keep Getting https://t.co/YP2quqpgsA https://t.co/9XK6AbYpeO\"\n",
      " u'Alarming New Adult Trend \\u2018Plateauing In Your Career And Relationship\\u2019 Sweeps Nation https://t.co/lqdaZmZkAS https://t.co/Ro2AgZjZFU'\n",
      " u'National News Highlights https://t.co/nI6924DWcR'\n",
      " u'Man Somehow Getting Worse At Sex https://t.co/Q3lkIxBhtI https://t.co/6TfIaBjOod']\n"
     ]
    }
   ],
   "source": [
    "print tweet_text[4:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'2ndgrade teacher cant believe how much fatter they keep getting url url', u'alarming new adult trend plateauing in your career and relationship sweeps nation url url', u'national news highlights url', u'man somehow getting worse at sex url url']\n"
     ]
    }
   ],
   "source": [
    "print clean_text[4:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# target is the handle.\n",
    "# make trump 1 and sanders 0\n",
    "import numpy as np\n",
    "y = tweets['handle'].map(lambda x: 1 if x == 'Donald J. Trump' else 0).values\n",
    "print np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Preprocess our text data to Tfidf\n",
    "tfv = TfidfVectorizer(ngram_range=(1,4), max_features=2000)\n",
    "X = tfv.fit_transform(clean_text).todense()\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.899\n",
      "0.899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validate the accuracy:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(LogisticRegression(), X, y, cv=10)\n",
    "\n",
    "print accuracies.mean()\n",
    "print np.mean(accuracies)\n",
    "\n",
    "# Setup logistic regression (or try another classification method here)\n",
    "estimator = LogisticRegression()\n",
    "estimator.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Very good accuracy considering the baseline is 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the predicted probability for a random Sanders and Trump tweet\n",
    "---\n",
    "\n",
    "Below are provided a couple of tweets from both Sanders and Trump. I'm sure you can figure out on your own which one is which.\n",
    "\n",
    "Estimate the predicted probability of being trump for the two tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.76219839,  0.23780161],\n",
       "       [ 0.37726024,  0.62273976]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prep our source as TfIdf vectors\n",
    "source_test = [\n",
    "    \"Demanding that the wealthy and the powerful start paying their fair share of taxes that's exactly what the American people want.\",\n",
    "    \"Crooked Hillary is spending tremendous amounts of Wall Street money on false ads against me. She is a very dishonest person!\"\n",
    "]\n",
    "\n",
    "############\n",
    "# NOTE:  Do not re-initialize the tfidf vectorizor or the feature space willbe overwritten and\n",
    "# hence your transform will not match the number of features you trained your model on.\n",
    "#\n",
    "# This is why you only need to \"transform\" since you already \"fit\" previously\n",
    "#\n",
    "####\n",
    "\n",
    "Xtest = tfv.transform(source_test)\n",
    "\n",
    "# Predict using previously trained logist regression `estimator`\n",
    "estimator.predict_proba(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The 1st column is probability of being Bernie, and 2nd Trump. The classifier is getting it right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent practice questions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pull tweets for some new users.\n",
    "\n",
    "Experiment with using more data.  The API will not like it if you blow through their limits - be careful.  Try to grab only what you need one time, then work on the copy of the objects that are returned.  \n",
    "\n",
    "> Read the documentation about rate limits and see if you can get enough without hitting the rate limit.  Are there any options available in the API to avoid such a problem?\n",
    "\n",
    "**Pull tweets for more than two different users of your choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining tweets for:  theonion\n",
      "Mining tweets for:  vice\n",
      "Mining tweets for:  warriors\n"
     ]
    }
   ],
   "source": [
    "# We deviate from trump / sanders using student tweets here to illustrate the NLP pipeine with twitter data\n",
    "\n",
    "twitter_handles = [\"theonion\", \"vice\",'warriors']\n",
    "tweets = {}\n",
    "\n",
    "for twitter_handle in twitter_handles:\n",
    "    print \"Mining tweets for: \", twitter_handle\n",
    "    miner = TweetMiner(twitter_keys, api, result_limit=500)\n",
    "    tweets[twitter_handle] = miner.mine_user_tweets(user=twitter_handle, max_pages=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 6)\n"
     ]
    }
   ],
   "source": [
    "multi = pd.DataFrame(tweets[twitter_handles[0]])\n",
    "multi = multi.append(pd.DataFrame((tweets[twitter_handles[1]])))\n",
    "multi = multi.append(pd.DataFrame((tweets[twitter_handles[2]])))\n",
    "\n",
    "print multi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build a multi-class classification model to distinguish between the users.\n",
    "\n",
    "Try a new type of model than we used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_text = multi['text'].values\n",
    "clean_text = [preprocess_text(x, fix_unicode=True, lowercase=True, transliterate=False,\n",
    "                              no_urls=True, no_emails=True, no_phone_numbers=True, no_currency_symbols=True,\n",
    "                              no_punct=True, no_accents=True)\n",
    "              for x in tweet_text]\n",
    "\n",
    "y = multi['handle'].apply(lambda x: 0 if x == \"The Onion\" else 1 if x == \"VICE\" else 2)\n",
    "X = pd.DataFrame({\"clean_text\":clean_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(ngram_range=(1,3), max_features=2500)\n",
    "# BEWARE! FIT-TRANSFORMING OUR TFIDFVECTORIZER ON OUR TRAIN, BUT ONLY TRANSFORMING OUR TEST!\n",
    "# We do this so that none of the top 2500 features come from the test data!\n",
    "X_train, X_test = tfv.fit_transform(X_train['clean_text']), tfv.transform(X_test['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 250 out of 250 | elapsed:    7.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=250, verbose=1)\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 250 out of 250 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.898888888889\n",
      "KNN: 0.460555555556\n"
     ]
    }
   ],
   "source": [
    "# Random forest score:\n",
    "print 'RF:', rf.score(X_test, y_test)\n",
    "print 'KNN:', knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VICE                   0.333333\n",
       "GoldenStateWarriors    0.333333\n",
       "The Onion              0.333333\n",
       "Name: handle, dtype: float64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline score:\n",
    "multi.handle.value_counts()/multi.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_yhat = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Make a confusion matrix and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.27      0.42       634\n",
      "          1       0.89      0.14      0.25       591\n",
      "          2       0.38      0.99      0.55       575\n",
      "\n",
      "avg / total       0.74      0.46      0.40      1800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print classification_report(y_test, rf_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[173   8 453]\n",
      " [ 12  85 494]\n",
      " [  1   3 571]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print confusion_matrix(y_test, rf_yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the most and least \"distinctive\" tweets for each user?\n",
    "\n",
    "To find this, identify the tweet that has the highest (correct) predicted probability of being that user's tweet for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 250 out of 250 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "pp = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.084,  0.104,  0.812],\n",
       "       [ 0.912,  0.088,  0.   ],\n",
       "       [ 0.02 ,  0.964,  0.016],\n",
       "       [ 0.964,  0.036,  0.   ],\n",
       "       [ 0.672,  0.288,  0.04 ]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = pd.DataFrame(pp, columns=['The_Onion_Prob', 'VICE_Prob', 'GoldenStateWarriors_Prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The_Onion_Prob</th>\n",
       "      <th>VICE_Prob</th>\n",
       "      <th>GoldenStateWarriors_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.084</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.964</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.672</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   The_Onion_Prob  VICE_Prob  GoldenStateWarriors_Prob\n",
       "0           0.084      0.104                     0.812\n",
       "1           0.912      0.088                     0.000\n",
       "2           0.020      0.964                     0.016\n",
       "3           0.964      0.036                     0.000\n",
       "4           0.672      0.288                     0.040"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200,) (4200, 3)\n"
     ]
    }
   ],
   "source": [
    "print y_train.shape, pp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>The_Onion_Prob</th>\n",
       "      <th>VICE_Prob</th>\n",
       "      <th>GoldenStateWarriors_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 25 15:29:05 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-08-25 11:33:26.074366</td>\n",
       "      <td>3</td>\n",
       "      <td>Today’s Weather Report https://t.co/oIlLmRF53p</td>\n",
       "      <td>901104150229811201</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Aug 25 15:13:02 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-08-25 11:33:26.074381</td>\n",
       "      <td>55</td>\n",
       "      <td>What You Need To Know About Taylor Swift https...</td>\n",
       "      <td>901100110892998656</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Aug 25 14:42:09 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-08-25 11:33:26.074386</td>\n",
       "      <td>166</td>\n",
       "      <td>College Roommates Surprised To Find Dorm Room ...</td>\n",
       "      <td>901092335995543553</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Aug 25 13:55:08 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-08-25 11:33:26.074390</td>\n",
       "      <td>146</td>\n",
       "      <td>Astronomers Discover Planet Identical To Earth...</td>\n",
       "      <td>901080503855591424</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Aug 25 13:08:07 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-08-25 11:33:26.074394</td>\n",
       "      <td>135</td>\n",
       "      <td>2nd-Grade Teacher Can't Believe How Much Fatte...</td>\n",
       "      <td>901068672311197696</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fri Aug 25 12:21:05 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-08-25 11:33:26.074399</td>\n",
       "      <td>204</td>\n",
       "      <td>Alarming New Adult Trend ‘Plateauing In Your C...</td>\n",
       "      <td>901056835662295044</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fri Aug 25 04:30:04 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-08-25 11:33:26.074404</td>\n",
       "      <td>14</td>\n",
       "      <td>National News Highlights https://t.co/nI6924DWcR</td>\n",
       "      <td>900938300600352768</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fri Aug 25 03:31:04 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-08-25 11:33:26.074408</td>\n",
       "      <td>140</td>\n",
       "      <td>Man Somehow Getting Worse At Sex https://t.co/...</td>\n",
       "      <td>900923454295347200</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fri Aug 25 02:32:06 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-08-25 11:33:26.074412</td>\n",
       "      <td>600</td>\n",
       "      <td>Flying Squirrel Loves It Every Time https://t....</td>\n",
       "      <td>900908613472014337</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fri Aug 25 01:33:02 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-08-25 11:33:26.074417</td>\n",
       "      <td>72</td>\n",
       "      <td>Alternative Birth Control Methods https://t.co...</td>\n",
       "      <td>900893749177335808</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at     handle                   mined_at  \\\n",
       "0  Fri Aug 25 15:29:05 +0000 2017  The Onion 2017-08-25 11:33:26.074366   \n",
       "1  Fri Aug 25 15:13:02 +0000 2017  The Onion 2017-08-25 11:33:26.074381   \n",
       "2  Fri Aug 25 14:42:09 +0000 2017  The Onion 2017-08-25 11:33:26.074386   \n",
       "3  Fri Aug 25 13:55:08 +0000 2017  The Onion 2017-08-25 11:33:26.074390   \n",
       "4  Fri Aug 25 13:08:07 +0000 2017  The Onion 2017-08-25 11:33:26.074394   \n",
       "5  Fri Aug 25 12:21:05 +0000 2017  The Onion 2017-08-25 11:33:26.074399   \n",
       "6  Fri Aug 25 04:30:04 +0000 2017  The Onion 2017-08-25 11:33:26.074404   \n",
       "7  Fri Aug 25 03:31:04 +0000 2017  The Onion 2017-08-25 11:33:26.074408   \n",
       "8  Fri Aug 25 02:32:06 +0000 2017  The Onion 2017-08-25 11:33:26.074412   \n",
       "9  Fri Aug 25 01:33:02 +0000 2017  The Onion 2017-08-25 11:33:26.074417   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              3     Today’s Weather Report https://t.co/oIlLmRF53p   \n",
       "1             55  What You Need To Know About Taylor Swift https...   \n",
       "2            166  College Roommates Surprised To Find Dorm Room ...   \n",
       "3            146  Astronomers Discover Planet Identical To Earth...   \n",
       "4            135  2nd-Grade Teacher Can't Believe How Much Fatte...   \n",
       "5            204  Alarming New Adult Trend ‘Plateauing In Your C...   \n",
       "6             14   National News Highlights https://t.co/nI6924DWcR   \n",
       "7            140  Man Somehow Getting Worse At Sex https://t.co/...   \n",
       "8            600  Flying Squirrel Loves It Every Time https://t....   \n",
       "9             72  Alternative Birth Control Methods https://t.co...   \n",
       "\n",
       "             tweet_id  The_Onion_Prob  VICE_Prob  GoldenStateWarriors_Prob  \n",
       "0  901104150229811201           0.084      0.104                     0.812  \n",
       "1  901100110892998656           0.912      0.088                     0.000  \n",
       "2  901092335995543553           0.020      0.964                     0.016  \n",
       "3  901080503855591424           0.964      0.036                     0.000  \n",
       "4  901068672311197696           0.672      0.288                     0.040  \n",
       "5  901056835662295044           0.928      0.024                     0.048  \n",
       "6  900938300600352768           1.000      0.000                     0.000  \n",
       "7  900923454295347200           0.064      0.920                     0.016  \n",
       "8  900908613472014337           0.000      0.000                     1.000  \n",
       "9  900893749177335808           0.992      0.000                     0.008  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_pp = pd.concat([multi.reset_index(), pp.reset_index()], axis=1)\n",
    "tweets_pp.drop('index', axis=1, inplace=True)\n",
    "tweets_pp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Onion-like: Rec Sports League Organizer Needs To Cool It With The Emails https://t.co/JXnYbW7owp https://t.co/OrkT6jQ9Cj\n",
      "Least Onion-like: Today's Weather Report https://t.co/1GkG5aaRAL\n"
     ]
    }
   ],
   "source": [
    "print 'Most Onion-like:', tweets_pp[tweets_pp.handle == 'The Onion'].sort_values('The_Onion_Prob', ascending=False).text.values[0]\n",
    "print 'Least Onion-like:', tweets_pp[tweets_pp.handle == 'The Onion'].sort_values('The_Onion_Prob', ascending=True).text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most VICE-like: \"If Batman teaches us anything, it's that not all rich people are dicks.” https://t.co/d0ABtwaW5l\n",
      "Least VICE-like: Michelle 'suicide-by-text' Carter just got sentenced to prison https://t.co/4KoaXihjjD https://t.co/BAVHrjhiez\n"
     ]
    }
   ],
   "source": [
    "print 'Most VICE-like:', tweets_pp[tweets_pp.handle == 'VICE'].sort_values('VICE_Prob', ascending=False).text.values[0]\n",
    "print 'Least VICE-like:', tweets_pp[tweets_pp.handle == 'VICE'].sort_values('VICE_Prob', ascending=True).text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most GoldenStateWarriors-like: ⛳️🏌🏾 @Andre is taking over the @PGA IG account for the #PGAChamp 👉🏽 https://t.co/qlqiERND8b https://t.co/DLY7aqyvms\n",
      "Least GoldenStateWarriors-like: RT @WebDotComTour: Right in the heart. 👌\n",
      "\n",
      "@StephenCurry30's first #WebTour par. ⛳️ https://t.co/uZPSbzAtHV\n"
     ]
    }
   ],
   "source": [
    "print 'Most GoldenStateWarriors-like:', tweets_pp[tweets_pp.handle == 'GoldenStateWarriors'].sort_values('GoldenStateWarriors_Prob', ascending=False).text.values[0]\n",
    "print 'Least GoldenStateWarriors-like:', tweets_pp[tweets_pp.handle == 'GoldenStateWarriors'].sort_values('GoldenStateWarriors_Prob', ascending=True).text.values[0]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
